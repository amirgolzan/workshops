---
title: "Menu"
pagetitle: "Menu"
---

# Workshop Outlines

> Dates and registration details available at [https://csc.ok.ubc.ca/workshops/](https://csc.ok.ubc.ca/workshops/)

## R Fundamentals for Data Analysis

[R: Fundamental Concepts with RStudio](R_fundamental-concepts-with-RStudio.html)

[R: Importing Data](R_importing-data.html)

[R: Exploring Data](R_exploring-data.html)

[R: Subsetting & Filtering Data](R_subsetting-and-filtering-data.html)

[R: Iterating Over Data](R_iterating-over-data.html)

[R: Conditions](R_conditions.html)

[R: Visualizations](R_visualization.html)

## Python Basics for Data Analysis

[Python: Fundamental Concepts with Jupyter Notebook](Python_fundamental-concepts-with-Jupyter-Notebook.html)

[Python: Importing and Exporting Data with Python](Python_importing-data.html)

[Python: Exploratory Data Analysis](Exploratory_Data_Analysis_Workshop3.html)

[Python: Subsetting and Filtering Data](Subsetting_and_Filtering_Data_Workshop4.html)

[Python: Iterating Over Data](Iterating_Over_Data_Workshop5.html)

[Python: Conditions](Python_conditions.html)

[Python: Visualizations](Python_Visualization.html)

[Python: Data Analysis and Visualization](Workshop8_Visualization_continued.html)

## Researcher Toolkit

### Research Data Management (RDM)

[RDM Part 1: The Basics](RDM_pt1-the-basics.html)

[RDM Part 2: Documentation](RDM_pt2-documentation.html)

[RDM Part 3: Data Management Plans](https://ubc-library-rc.github.io/rdm/content/06_Data_Management_Plan.html)


### Introduction to the Shell

[Introduction to the Unix Shell Part 1: Navigating Files and Directories](UNIX_pt1.html)

[Introduction to the Unix Shell Part 2: Working with Files and Directories](UNIX_pt2.html)

## GitHub and GitHub Pages

[Introduction to GitHub Part 1](Intro-GitHub-Part-1.html)

[Introduction to GitHub Part 2](Intro-GitHub-Part-2.html)

## Statistical Fundamentals: A Visual Approach

This series will use R and Python to help develop an intuition for fundamental statistical concepts using data visualization. These workshops are equally suitable to those hoping to enhance their ability to interpret common statistical tests and concepts as it is for those applying statistical modelling to their work. No background in statistics is required, but some familiarity with R or Python will be advantageous. 

You may wish to review the asynchronous content of either [R Fundamentals for Data Anlysis](https://csc-ubc-okanagan.github.io/workshops/#r-fundamentals-for-data-analysis) or [Python Basics for Data Analysis](https://csc-ubc-okanagan.github.io/workshops/#python-basics-for-data-analysis), or keep an eye out for the next time these workshops are offered.

**Population, Sampling, Sampling Distribution, and Central Limit Theorem**

This session will introduce participants to the foundational concepts of statistical inference, including population distributions and the process of random sampling. Attendees will learn how sampling distributions evolve towards normality as sample sizes increase and will visually explore the Central Limit Theorem.

By the end of the session, participants should be able to visualize and understand population distributions, illustrate random sampling processes, recognize the normalizing effect of larger samples on sampling distributions, and demonstrate the Central Limit Theorem visually.

**Visualizing Errors and Common Pitfalls**

This session will address the visualization of standard deviation (s.d.), standard error of the mean (s.e.m.), and confidence interval (CI) error bars to enhance the understanding of uncertainty in data analysis. The interpretation of error bars for statistical significance will be discussed, along with common misinterpretations to avoid.

By the end of the session, participants should be able to visualize and interpret error bars, understand the implications of their spacing and width, and be cautious of common pitfalls such as misinterpreting non-overlapping error bars as evidence of significance.

**P value, Significance, and T-test**

This session will introduce participants to the concept of P values and their role in hypothesis testing, highlighting that P values reflect the probability of observing the data under the null hypothesis, not the biological significance of the findings. The session will cover the computation of P values and delve into the nuances of one-sample t-tests.

By the end of the session, participants should be able to comprehend the meaning of P values, understand how hypothesis tests calculate P values, recognize when small P values indicate unlikely events under the null hypothesis, and explore the assumptions behind one-sample t-tests.

**Visualizing samples with Boxplots: Kick the Bar chart habit**

This session will address the advantages of box plots over bar charts for displaying the spread and variability in data. Participants will learn how box plots can be used to compare multiple samples, the impact of sample size on data representation, and the efficient identification of outliers.

By the end of the session, participants should be able to create and interpret box plots, appreciate their usefulness in comparing multiple samples, understand the implications of sample size, and identify outliers and median confidence intervals through notches in box plots.


**All about t-tests and visualizations**

This session will introduce participants to the various types of t-tests, including one-sample, two-sample, paired, and one-sided tests. Attendees will learn about the appropriate applications for each type and the visualization techniques that can enhance the interpretation of t-test results.

By the end of the session, participants should be able to apply and visually represent different t-tests, interpret their results, understand the implications of multiple testing corrections, and select the appropriate test for their data.

**Non-parametric tests and visualizations**

This session will introduce participants to non-parametric tests, which are useful when data distributions do not meet the assumptions of parametric tests. Attendees will learn to compare the adaptability of these tests with different data distributions and to visualize their operation.

By the end of the session, participants should be able to choose and apply the appropriate non-parametric tests for their data, visualize the operation of these tests, and understand the challenges of multiple testing with non-parametric methods.

**ANOVA and Blocking**

This session will introduce participants to the Analysis of Variance (ANOVA), a statistical method used for comparing the means of three or more groups. The concept of blocking will also be introduced to reduce noise and isolate sources of variation.

By the end of the session, participants should be able to use ANOVA for multi-treatment analysis, implement blocking in experimental design, calculate the F statistic for assessing significance, and appreciate how blocking can improve the efficiency of a study.

**Correlation, causation, and association**

This session will address the concepts of correlation, causation, and association in data. Participants will learn to differentiate between these concepts and to recognize and interpret various types of correlations.

By the end of the session, participants should be able to distinguish between correlation and causation, recognize the impact of confounding variables on associations, evaluate correlation reliability, and understand the significance of correlation results.

## Fitting Models to Data Not Data to Models

You might have heard someone say that "all models are wrong, but some are useful". The best way to ensure models are useful is to choose a model that is appropriate to your data and research questions, rather than forcing your data to fit your model's assumptions (e.g., normality, independence, constant variance).

This series introduces early-career researchers to statistical models that extend beyond linear models (i.e., ANOVAs) so that they may learn how to *fit models to their data rather than fitting their data to models*. All workshops will use `R` and RStudio, so some experience with `R` or other programming languages is encouraged but not required. See the [R Fundamentals for Data Anlysis](https://csc-ubc-okanagan.github.io/workshops/#r-fundamentals-for-data-analysis) for an introduction to `R` and RStudio. Attendees who do not have experience with `R` are encouraged to review this content or take the introductory workshop concurrently if it's being offered.

**Single Linear Regression**

This workshop will introduce linear models (i.e., one-way ANOVAs), their assumptions, and limitations, in a format tailored towards visual and spatial learners.

By the end of the session, participants should be able to visualize and explain single linear regression models, their assumptions, and their limitations.

**Fitting linear models in `R`**

This workshop will illustrate how to fit linear models in `R`, diagnose any issues with model assumption violations, and interpret linear model summaries, including model coefficients, degrees of freedom, standard error estimates, $t$ statistics, $F$ statistics, p-values, $R^2$, statistical significance, adjusted $R^2$.

By the end of this session, participants will be able to fit linear models in `R` and interpret model outputs, including the output of the `summary()` function in `R`.

**Multiple linear regression in `R`**

This workshop will demystify ANOVAs by framing them in the context of linear models with multiple predictors (i.e. multiple linear regression). The session will also introduce attendees to Directed Acyclical Graphs (DAGs) and demonstrate how to use them to infer causality in one's model.

By the end of this session participants should be able to fit linear models with more than one predictor, check for collinearity between predictors, and interpret linear models using DAGs.

**Interaction terms and Hierarchical Linear Models/Linear Mixed Models**

This workshop will introduce interaction terms in linear models along with random and fixed effects, including random and fixed intercepts and slopes, in the context of Hierarchical Linear Models (also known as Linear Mixed Models).

By the end of this session, participants should be able to fit (Hierarchical) Linear Models (HLMs) with interaction terms and interpret the output of the `summary()` function for Hierarchical Linear Models. Additionally, participants will be able to identify the limitations of (H)LMs.

**(Hierarchical) Generalized Linear Models**

This workshop will introduce Generalized Linear Models (GLMs), which allow one to model non-Gaussian (i.e., non-normal) data.

By the end of this session, participants will be familiar with the three parts of GLMs (family of distribution, linear predictor, and link function) and will be able to decide what family of distributions and link function to choose for their data. They will also be able to interpret the output of the `summary()` function and diagnostic plots for (H)GLMs and recognize the limitations of (H)GLMs. 

**Generalized Additive Models**

This workshop will introduce Generalized Additive Models (GAMs), which allow one to fit models that are complex and nonlinear but easily interpretable, unlike many "black-box" machine learning models.

By the end of this session, participants will be able to fit GAMs in `R` using the `mgcv` package and understand the advantages of GAMs over GLMs and LMs.

**Interpreting and predicting from Generalized Additive Models**

This workshop will show how to interpret GAMs and how to use GAMs to make publication-level figures.

By the end of this session, participants should be able to interpret GAMs and the output of the `summary()` function, predict from GAMs, and make figures using GAMs.

**Hierarchical GAMs**

This workshop will re-visit random and fixed effects with Hierachical GAMs (HGAMs) and expand the concepts of random slopes by introducing random smooths. The workshop will also cover smooth, nonlinear interaction terms via the `ti()` and `te()` functions.

By the end of this session, participants should be able to fit HGAMs with smooth interaction terms, plot and interpret the models.





